<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TASC - Theory of AI for Scientific Computing</title>
    <style>
        :root {
            --primary-color: #3498db;
            --secondary-color: #2980b9;
            --accent-color: #e74c3c;
            --text-color: #333;
            --light-bg: #f9f9f9;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: white;
        }
        
        a {
            color: var(--primary-color);
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        .container {
            max-width: 1100px;
            margin: 0 auto;
            padding: 0 20px;
        }
        
        header {
            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
            color: white;
            padding: 60px 0;
            text-align: center;
        }
        
        header h1 {
            font-size: 2.5rem;
            margin-bottom: 15px;
        }
        
        header p {
            font-size: 1.2rem;
            max-width: 800px;
            margin: 0 auto;
        }
        
        nav {
            background-color: white;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            position: sticky;
            top: 0;
            z-index: 100;
        }
        
        nav ul {
            display: flex;
            justify-content: center;
            list-style: none;
            flex-wrap: wrap;
        }
        
        nav ul li {
            padding: 15px 20px;
        }
        
        nav ul li a {
            color: var(--text-color);
            font-weight: 500;
        }
        
        nav ul li a:hover {
            color: var(--primary-color);
            text-decoration: none;
        }
        
        section {
            padding: 60px 0;
        }
        
        section:nth-child(even) {
            background-color: var(--light-bg);
        }
        
        .section-heading {
            text-align: center;
            margin-bottom: 40px;
        }
        
        .section-heading h2 {
            font-size: 2rem;
            color: var(--secondary-color);
            position: relative;
            display: inline-block;
            padding-bottom: 10px;
        }
        
        .section-heading h2::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 50%;
            transform: translateX(-50%);
            width: 50px;
            height: 3px;
            background-color: var(--accent-color);
        }
        
        .speakers-container {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 30px;
        }
        
        .speaker-card {
            background-color: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 3px 10px rgba(0,0,0,0.1);
            width: 300px;
            transition: transform 0.3s, box-shadow 0.3s;
        }
        
        .speaker-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.15);
        }
        
        .speaker-image {
            width: 100%;
            height: 200px;
            background-color: #ddd;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .speaker-info {
            padding: 20px;
        }
        
        .speaker-info h3 {
            margin-bottom: 5px;
            color: var(--secondary-color);
        }
        
        .speaker-info p.affiliation {
            color: var(--accent-color);
            font-weight: 500;
            margin-bottom: 10px;
        }
        
        .schedule-container {
            max-width: 700px;
            margin: 0 auto;
        }
        
        .schedule-table {
            background-color: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        }
        
        .schedule-row {
            display: flex;
            align-items: center;
            border-bottom: 1px solid #f0f0f0;
            padding: 15px 0;
        }
        
        .schedule-row:last-child {
            border-bottom: none;
        }
        
        .schedule-row:hover {
            background-color: var(--light-bg);
        }
        
        .schedule-time {
            background-color: var(--primary-color);
            color: white;
            padding: 8px 15px;
            border-radius: 6px;
            font-weight: 600;
            min-width: 90px;
            text-align: center;
            font-size: 0.9rem;
            margin: 0 25px;
        }
        
        .schedule-event {
            flex: 1;
            font-size: 1rem;
            color: var(--text-color);
            margin-right: 25px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            gap: 15px;
        }

        .event-info {
            flex: 1;
        }

        .event-info strong {
            color: var(--secondary-color);
        }

        .event-info em {
            color: var(--text-color);
            font-size: 0.95rem;
        }

        .details-btn {
            background-color: var(--accent-color);
            color: white;
            border: none;
            padding: 6px 12px;
            border-radius: 4px;
            font-size: 0.85rem;
            cursor: pointer;
            transition: background-color 0.3s;
            margin-left: 15px;
        }

        .details-btn:hover {
            background-color: #c0392b;
        }

        .keynote-details {
            display: none;
            background-color: var(--light-bg);
            border-left: 4px solid var(--accent-color);
            margin: 0 25px 0 115px;
            animation: slideDown 0.3s ease-out;
        }

        .keynote-details.show {
            display: block;
        }

        .details-content {
            padding: 20px;
        }

        .details-content h4 {
            color: var(--secondary-color);
            margin-bottom: 10px;
            font-size: 1.1rem;
        }

        .details-content p {
            line-height: 1.6;
            margin: 0;
        }

        @keyframes slideDown {
            from {
                opacity: 0;
                max-height: 0;
            }
            to {
                opacity: 1;
                max-height: 200px;
            }
        }
        
        .cfp {
            max-width: 800px;
            margin: 0 auto;
        }
        
        .cfp ul {
            margin-left: 20px;
            margin-bottom: 20px;
        }
        
        .dates-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }
        
        .date-card {
            background-color: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        }
        
        .date-card h3 {
            color: var(--accent-color);
            font-size: 1.2rem;
            margin-bottom: 10px;
        }
        
        .organizers-container {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 30px;
            margin-top: 30px;
        }
        
        .organizer-card {
            text-align: center;
            width: 180px;
        }
        
        .organizer-image {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            background-color: #ddd;
            margin: 0 auto 15px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .submission-button {
            display: inline-block;
            background-color: var(--accent-color);
            color: white;
            padding: 12px 30px;
            border-radius: 4px;
            font-weight: 600;
            margin-top: 20px;
            transition: background-color 0.3s;
        }
        
        .submission-button:hover {
            background-color: #c0392b;
            text-decoration: none;
        }
        
        footer {
            background-color: #333;
            color: white;
            text-align: center;
            padding: 30px 0;
        }
        
        @media (max-width: 768px) {
            header {
                padding: 40px 0;
            }
            
            header h1 {
                font-size: 2rem;
            }
            
            nav ul {
                flex-wrap: wrap;
            }
            
            .speakers-container {
                gap: 20px;
            }
            
            .speaker-card {
                width: 100%;
                max-width: 300px;
            }
            
            .schedule-row {
                flex-direction: column;
                gap: 10px;
                align-items: flex-start;
                padding: 15px 20px;
            }
            
            .schedule-time {
                margin: 0;
                align-self: flex-start;
            }
            
            .schedule-event {
                margin: 0;
                flex-direction: column;
                align-items: flex-start;
                gap: 10px;
            }
            
            .event-info {
                width: 100%;
            }
            
            .details-btn {
                margin-left: 0;
                align-self: flex-start;
            }
            
            .keynote-details {
                margin: 0 20px;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>Theory of AI for Scientific Computing</h1>
            <p>Official website of the TASC workshop, to be held June 30, 2025 as part of <a href="https://learningtheory.org/colt2025/index.html" target="_blank" style="color: white; text-decoration: underline;">COLT 2025</a></p>
        </div>
    </header>
    
    <nav>
        <ul>
            <li><a href="#about">About</a></li>
            <li><a href="#speakers">Speakers</a></li>
            <li><a href="#schedule">Schedule</a></li>
            <li><a href="#cfp">Call for Papers</a></li>
            <li><a href="#submission">Submission</a></li>
            <li><a href="#dates">Important Dates</a></li>
            <li><a href="#organizers">Organizers</a></li>
            <li><a href="#registration">Registration</a></li>
        </ul>
    </nav>
    
    <section id="about">
        <div class="container">
            <div class="section-heading">
                <h2>About TASC</h2>
            </div>
            <p>
                The Theory of AI for Scientific Computing (TASC) workshop will be held as part of COLT 2025 and aims to advance the theoretical understanding of AI-augmented scientific computing, including capabilities and limitations of recent methods, principled architectures, unique data-generation and training considerations when connecting ML to downstream tasks, the sample complexity potential of transfer learning and active sampling, and ensuring the robustness of deployed systems and the validity of new discoveries.
                Our goal is to foster new theory that can bridge the gap between rapid methodological developments and their ultimate goals:
scientific understanding and deployable computational systems.
                Join us on June 30, 2025 in Lyon, France for an exciting program of keynotes, posters, awards, and discussions about building principled connections between learning, algorithms, and the physical sciences, identifying promising scientific computing objectives for AI, and formalizing theoretical problems that will inspire continued progress.
            </p>
        </div>
    </section>
    
    <section id="speakers">
        <div class="container">
            <div class="section-heading">
                <h2>Keynote Speakers</h2>
            </div>
            <div class="speakers-container">
                
                <div class="speaker-card">
                    <div class="speaker-image">
                        <img src="joan.jpg" alt="Joan Bruna">
                    </div>
                    <div class="speaker-info">
                        <h3><a href="https://cims.nyu.edu/~bruna/" target="_blank">Joan Bruna</a></h3>
                        <p class="affiliation">New York University</p>
                        <p>CS, Data Science, &amp; Mathematics</p>
                        <em>On Inverse Problems and Diffusion</em>
                    </div>
                </div>
                
                <div class="speaker-card">
                    <div class="speaker-image">
                        <img src="aditi.jpeg" alt="Aditi Krishnapriyan">
                    </div>
                    <div class="speaker-info">
                        <h3><a href="https://a1k12.github.io" target="_blank">Aditi Krishnapriyan</a></h3>
                        <p class="affiliation">UC Berkeley</p>
                        <p>Chemical Engineering &amp; EECS</p>
                        <em>Physics-Informed Machine Learning: Theory and Practice</em>
                    </div>
                </div>

                <div class="speaker-card">
                    <div class="speaker-image">
                        <img src="houman.jpg" alt="Houman Owhadi">
                    </div>
                    <div class="speaker-info">
                        <h3><a href="http://users.cms.caltech.edu/~owhadi/" target="_blank">Houman Owhadi</a></h3>
                        <p class="affiliation">California Institute of Technology</p>
                        <p>Computing &amp; Mathematical Sciences</p>
                        <em>Operator Learning and Computational Homogenization</em>
                    </div>
                </div>

            </div>
        </div>
    </section>
    
    <section id="schedule">
        <div class="container">
            <div class="section-heading">
                <h2>Workshop Schedule</h2>
            </div>
            <div class="schedule-container">
                <p style="text-align: center; margin-bottom: 30px; font-style: italic;">June 30, 2025 • Mérieux Amphitheater, ENS Lyon • All times in Central European Time (CET)</p>
                
                <div class="schedule-table">
                    <div class="schedule-row">
                        <div class="schedule-time">9:00 AM</div>
                        <div class="schedule-event">Welcoming remarks</div>
                    </div>
                    
                    <div class="schedule-row">
                        <div class="schedule-time">9:05 AM</div>
                        <div class="schedule-event">
                            <div class="event-info">
                                <strong>Joan Bruna (NYU)</strong><br>
                                <em>On Inverse Problems and Diffusion</em>
                            </div>
                            <button class="details-btn" onclick="toggleDetails('keynote1')" data-show-text="View Abstract" data-hide-text="Hide Abstract">View Abstract</button>
                        </div>
                    </div>
                    <div class="keynote-details" id="keynote1">
                        <div class="details-content">
                          <p><strong>Abstract:</strong> Transport-based models, such as diffusion or flow-matching, have become a leading 
framework for generative modeling, by reducing the task to modeling conditional expectations under suitable "noise" semigroups. 
In this talk, we will describe how these models can be adapted beyond generative modeling to the setting of inverse problems. 
We will focus on two snippets: (i) performing provable posterior sampling in the context of linear inverse problems, and (ii) learning 
a generative model from corrupted measurements, akin to solving another linear inverse problem, this time in the space of distributions. 
Joint work with Jiequn Han, Chirag Modi and Eric Vanden-Eijnden.</p>
                        </div>
                    </div>
                    
                    <div class="schedule-row">
                        <div class="schedule-time">9:45 AM</div>
                        <div class="schedule-event">
                            <div class="event-info">
                                <strong>Houman Owhadi (Caltech)</strong><br>
                                <em>Data-Efficient Kernel Methods for Learning Differential Equations and Their Solution Operators: Algorithms and Error Analysis</em>
                            </div>
                            <button class="details-btn" onclick="toggleDetails('keynote2')" data-show-text="View Abstract" data-hide-text="Hide Abstract">View Abstract</button>
                        </div>
                    </div>
                    <div class="keynote-details" id="keynote2">
                        <div class="details-content">
                          <p><strong>Abstract:</strong> We introduce a novel kernel-based framework for learning differential equations and their solution maps, which is efficient in terms of data requirements (both the number of solution examples and the amount of measurements from each example), as well as computational cost and training procedures. Our approach is mathematically interpretable and supported by rigorous theoretical guarantees in the form of quantitative worst-case error bounds for the learned equations and solution operators. Numerical benchmarks demonstrate significant improvements in computational complexity and robustness, achieving one to two orders of magnitude improvement in accuracy compared to state-of-the-art algorithms. This presentation is based on joint work with Yasamin Jalalian, Juan Felipe Osorio Ramirez, Alexander Hsu, and Bamdad Hosseini. A preprint is available at: <a href=https://arxiv.org/abs/2503.01036>https://arxiv.org/abs/2503.01036</a>.</p>
                        </div>
                    </div>

                    <div class="schedule-row">
                        <div class="schedule-time">10:25 AM</div>
                        <div class="schedule-event">
                            <div class="event-info">
                                Coffee break and poster setup
                            </div>
                            <button class="details-btn" onclick="toggleDetails('posters1')" data-show-text="View Accepted Posters" data-hide-text="Hide Posters">View Accepted Posters</button>
                        </div>
                    </div>
                    <div class="keynote-details" id="posters1">
                        <div class="details-content">
                          <div>
    <a href="https://openreview.net/forum?id=O7YgvPePse">Universal Approximation of Mean-Field Models via Transformers</a><br>
    Authors: Shiba Biswal, Karthik Elamvazhuthi, Rishi Sonthalia
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=iUppQcPAMK">Student-t processes as infinite-width limits of posterior BNNs</a><br>
    Authors: Francesco Caporali, Stefano Favaro, Dario Trevisan
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=lknSpGLyI8">Classes of bounded functions that are semantically equivalent to Turing-machine are PAC learnable</a><br>
    Author: Kevin Xu
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=ZCH6z1i7eU">Matrix-Free Two-to-Infinity and One-to-Two Norms Estimation</a><br>
    Authors: Askar Tsyganov, Sergey Samsonov, Maxim Rakhuba
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=VqycjZACPS">Translation-Equivariance of Normalization Layers and Aliasing in Convolutional Neural Networks</a><br>
    Authors: Jérémy Scanvic, Quentin Barthélemy, Julián Tachella
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=rKZkotB0um">BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs</a><br>
    Authors: Jerry Weihong Liu, Yasa Baig, Denise H. J. Lee, Rajat Vadiraj Dwaraknath, Atri Rudra, Christopher Re
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=1PPbK8uklp">Query Efficient Structured Matrix Approximation</a><br>
    Authors: Noah Amsel, Pratyush Avi, Tyler Chen, Feyza Duman Keles, Chinmay Hegde, Christopher Musco, Cameron N. Musco, David Persson
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=APd65s5NAK">Generalized Lie Symmetries in Physics-Informed Neural Operators</a><br>
    Authors: Amy Xiang Wang, Zakhar Shumaylov, Peter Zaika, Ferdia Sherry, Carola-Bibiane Schönlieb
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=tS4vGObuCA">Enhancing Physics-Informed Neural Networks Through Feature Engineering</a><br>
    Authors: Shaghayegh Fazliani, Zachary Frangella, Ya-Chi Chu, Madeleine Udell
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=W2TVe58Rp2">Stochastic Differential Policy Optimization: A Rough Path Approach to Reinforcement Learning</a><br>
    Authors: Minh Phuong Nguyen, Chandrajit L. Bajaj
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=xmTo6lOQkg">On the upper bounds for the matrix spectral norm</a><br>
    Authors: Ryapolov Denis, Maxim Rakhuba, Sergey Samsonov, Alexey Naumov
    <br></br>
</div>
                        </div>
                    </div>
                    

                    <div class="schedule-row">
                        <div class="schedule-time">11:00 AM</div>
                        <div class="schedule-event">
                            <div class="event-info">
                                <strong>Contributed Talk: Xiang Wang</strong><br>
                                <em>Generalized Lie Symmetries in Physics-Informed Neural Operators</em>
                            </div>
                            <button class="details-btn" onclick="toggleDetails('contributed1')" data-show-text="View Abstract" data-hide-text="Hide Abstract">View Abstract</button>
                        </div>
                    </div>
                    <div class="keynote-details" id="contributed1">
                        <div class="details-content">
                          <p><strong>Abstract:</strong> Physics-informed neural operators (PINOs) have emerged as powerful tools for learning solution operators of partial differential equations (PDEs). Recent research has demonstrated that incorporating Lie point symmetry information can significantly enhance the training efficiency of PINOs, primarily through techniques like data, architecture, and loss augmentation. In this work, we focus on the latter, highlighting that point symmetries oftentimes result in no training signal, limiting their effectiveness in many problems. To address this, we propose a novel loss augmentation strategy that leverages evolutionary representatives of point symmetries, a specific class of generalized symmetries of the underlying PDE. These generalized symmetries provide a richer set of generators compared to standard symmetries, leading to a more informative training signal. We demonstrate that leveraging evolutionary representatives enhances the performance of neural operators, resulting in improved data efficiency and accuracy during training.</p>
                        </div>
                    </div>

                    <div class="schedule-row">
                        <div class="schedule-time">11:10 AM</div>
                        <div class="schedule-event">
                            <div class="event-info">
                                <strong>Contributed Talk: Jerry Liu</strong><br>
                                <em>BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs</em>
                            </div>
                            <button class="details-btn" onclick="toggleDetails('contributed2')" data-show-text="View Abstract" data-hide-text="Hide Abstract">View Abstract</button>
                        </div>
                    </div>
                    <div class="keynote-details" id="contributed2">
                        <div class="details-content">
                          <p><strong>Abstract:</strong> Physics-informed neural networks (PINNs) offer a flexible way to solve partial differential equations (PDEs) with machine learning, yet they still fall well short of the machine-precision accuracy many scientific tasks demand. This motivates an investigation into whether the precision ceiling comes from the ill-conditioning of the PDEs themselves or from the typical multi-layer perceptron (MLP) architecture. We introduce the Barycentric Weight Layer (BWLer), which models the PDE solution through barycentric polynomial interpolation. A BWLer can be added on top of an existing MLP (a BWLer-hat) or replace it completely (explicit BWLer), cleanly separating how we represent the solution from how we take its derivatives for the physics loss. Using BWLer, we identify fundamental precision limitations within the MLP: on a simple 1-D interpolation task, even MLPs with O(10<sup>5</sup>) parameters stall around 10<sup>-8</sup> relative error -- about eight orders above float64 machine precision -- before any PDE terms are added. In PDE learning, adding a BWLer lifts this ceiling and exposes a tradeoff between achievable accuracy and the conditioning of the PDE loss. For linear PDEs we fully characterize this tradeoff with an explicit error decomposition and navigate it during training with spectral derivatives and preconditioning. Across five benchmark PDEs, adding a BWLer on top of an MLP improves relative error by up to 30x for convection, 10x for reaction, and 1800x for wave equations while remaining compatible with first-order optimizers. Replacing the MLP entirely lets an explicit BWLer reach near-machine-precision on convection, reaction, and wave problems (up to 10 billion times better than prior results) and match the performance of standard PINNs on stiff Burgers’ and irregular-geometry Poisson problems. Together, these findings point to a practical path for combining the flexibility of PINNs with the precision of classical spectral solvers.</p>
                        </div>
                    </div>
                    
                    <div class="schedule-row">
                        <div class="schedule-time">11:20 AM</div>
                        <div class="schedule-event">
                            <div class="event-info">
                                <strong>Aditi Krishnapriyan (UC Berkeley)</strong><br>
                                <em>Machine learning methods for science: physics insights leveraging data at scale</em>
                            </div>
                            <button class="details-btn" onclick="toggleDetails('keynote3')" data-show-text="View Abstract" data-hide-text="Hide Abstract">View Abstract</button>
                        </div>
                    </div>
                    <div class="keynote-details" id="keynote3">
                        <div class="details-content">
                          <p><strong>Abstract:</strong> TBA.</p>
                        </div>
                    </div>
                    
                    <div class="schedule-row">
                        <div class="schedule-time">12:00 PM</div>
                        <div class="schedule-event">
                            <div class="event-info">
                                Poster session
                            </div>
                            <button class="details-btn" onclick="toggleDetails('posters2')" data-show-text="View Accepted Posters" data-hide-text="Hide Posters">View Accepted Posters</button>
                        </div>
                    </div>
                    <div class="keynote-details" id="posters2">
                        <div class="details-content">
                          <div>
    <a href="https://openreview.net/forum?id=O7YgvPePse">Universal Approximation of Mean-Field Models via Transformers</a><br>
    Authors: Shiba Biswal, Karthik Elamvazhuthi, Rishi Sonthalia
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=iUppQcPAMK">Student-t processes as infinite-width limits of posterior BNNs</a><br>
    Authors: Francesco Caporali, Stefano Favaro, Dario Trevisan
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=lknSpGLyI8">Classes of bounded functions that are semantically equivalent to Turing-machine are PAC learnable</a><br>
    Author: Kevin Xu
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=ZCH6z1i7eU">Matrix-Free Two-to-Infinity and One-to-Two Norms Estimation</a><br>
    Authors: Askar Tsyganov, Sergey Samsonov, Maxim Rakhuba
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=VqycjZACPS">Translation-Equivariance of Normalization Layers and Aliasing in Convolutional Neural Networks</a><br>
    Authors: Jérémy Scanvic, Quentin Barthélemy, Julián Tachella
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=rKZkotB0um">BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs</a><br>
    Authors: Jerry Weihong Liu, Yasa Baig, Denise H. J. Lee, Rajat Vadiraj Dwaraknath, Atri Rudra, Christopher Re
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=1PPbK8uklp">Query Efficient Structured Matrix Approximation</a><br>
    Authors: Noah Amsel, Pratyush Avi, Tyler Chen, Feyza Duman Keles, Chinmay Hegde, Christopher Musco, Cameron N. Musco, David Persson
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=APd65s5NAK">Generalized Lie Symmetries in Physics-Informed Neural Operators</a><br>
    Authors: Amy Xiang Wang, Zakhar Shumaylov, Peter Zaika, Ferdia Sherry, Carola-Bibiane Schönlieb
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=tS4vGObuCA">Enhancing Physics-Informed Neural Networks Through Feature Engineering</a><br>
    Authors: Shaghayegh Fazliani, Zachary Frangella, Ya-Chi Chu, Madeleine Udell
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=W2TVe58Rp2">Stochastic Differential Policy Optimization: A Rough Path Approach to Reinforcement Learning</a><br>
    Authors: Minh Phuong Nguyen, Chandrajit L. Bajaj
    <br></br>
</div>

<div>
    <a href="https://openreview.net/forum?id=xmTo6lOQkg">On the upper bounds for the matrix spectral norm</a><br>
    Authors: Ryapolov Denis, Maxim Rakhuba, Sergey Samsonov, Alexey Naumov
    <br></br>
</div>
                        </div>
                    </div>
                    
                </div>
                
            </div>
        </div>
    </section>
    
    <section id="cfp">
        <div class="container">
            <div class="section-heading">
                <h2>Call for Papers</h2>
            </div>
            <div class="cfp">
                <p> We invite submissions at the interface of learning theory, statistics, numerical methods, algorithm design, and the physical sciences. 
                    Submissions may be of any length; in particular, we welcome both short poster abstracts and multi-page papers.
                    The topics of the workshop include (but are not limited to) the following:</p>
                <br>
                <ul>
                  <i>Learning-theoretic foundations</i>
                  <ul>
                    <li>learning-theoretic and statistical analysis of data-driven solutions to important scientific computing tasks such as solving differential equations, inverse problems, sampling, equation discovery, and beyond</li>
                    <li>mathematical characterizations of settings in which AI-augmented methods can be expected to improve over traditional (AI-free) scientific computing methods</li>
                    <li>end-to-end theoretical studies that consider simultaneously the entire scientific computing pipeline, i.e. not only learning from data but also generating the data itself and integrating the learned model into downstream scientific computing tasks</li>
                    <li>non-i.i.d. settings such as active sampling of ground truth solutions, reinforcement learning (RL) of equations and solvers, and transfer learning between different differential equation families, different solution domains, and different initial or boundary conditions</li>
                    <li>formalizing concrete goals for scientific discovery</li>
                  </ul>
                  <i>Principled methods for AI-augmented scientific computing</i>
                  <ul>
                    <li>theoretically-motivated design of neural architectures and loss functions for scientific computing tasks</li>
                    <li>mathematical connections between generative modeling and tractable solutions of high-dimensional PDEs</li>
                    <li>principled approaches to data-generation, model training, and model deployment</li>
                    <li>statistical machinery for certifying the quality and confidence of AI-augmented algorithms and improving their robustness</li>
                  </ul>
                  <i>Connections with other subfields of theory</i>
                  <ul>
                    <li>sampling</li>
                    <li>learning-augmented algorithms (algorithms with predictions) and data-driven algorithm design</li>
                    <li>optimization</li>
                    <li>randomized numerical linear algebra</li>
                  </ul>
                </ul>
                
                <p><strong>Submission criteria:</strong></p>
                <p>
                Papers and abstracts should be submitted as PDF files in any format that has a font size of at least 10 points and margins of at least 1 inch. 
                Submissions are not limited in length, but only the first 8 pages are guaranteed to be reviewed.
                Accepted submissions will be made public on OpenReview but are non-archival, and we welcome work accepted at previous or upcoming conferences, including COLT 2025 and ICML 2025.
                </p>
                <br>
                <p><strong>Reviewing and publication:</strong></p>
                All submissions will undergo a double-blind peer review process assessing mainly relevance, clarity, and soundness.
                Reviewing will occur on the OpenReview platform but reviews will not be public.
                Authors of accepted submissions will be invited to present a poster about it on the day of the workshop (June 30).
                The organizers will also select up to two submissions to receive best paper and runner-up awards, and their authors will have the opportunity to present short contributed talks.
                </p>

            </div>
        </div>
    </section>
    
    <section id="submission">
        <div class="container" style="text-align: center;">
            <div class="section-heading">
                <h2>Paper Submission</h2>
            </div>
            <div class="cfp">
            <p>Submissions can be made through the OpenReview link below; if registering an account there we recommended using an institutional email to avoid an up to two-week moderation period. Please ensure that you follow the submission guidelines outlined in the <a href="#cfp">Call for Papers</a>.</p>
            <a href="https://openreview.net/group?id=learningtheory.org/COLT/2025/Workshop/TASC" class="submission-button">Submission Link</a>
            <p style="margin-top: 20px;">For any questions regarding the submission process, please contact: <a href="mailto:tasc.organizers@gmail.com">tasc.organizers@gmail.com</a></p>
            </div>
        </div>
    </section>
    
    <section id="dates">
        <div class="container" style="text-align: center;">
            <div class="section-heading">
                <h2>Important Dates</h2>
            </div>
            <div class="dates-grid">
                <div class="date-card">
                    <h3>Paper Submission Deadline</h3>
                    <p><s>May 16, 2025</s><br><b>May 23, 2025</b></p>
                </div>
                
                <div class="date-card">
                    <h3>Notification of Acceptance</h3>
                    <p>June 1, 2025</p>
                </div>
                
                <div class="date-card">
                    <h3>Camera-Ready Deadline</h3>
                    <p>June 15, 2025</p>
                </div>
                
                <div class="date-card">
                    <h3>Workshop Date</h3>
                    <p>June 30, 2025</p>
                </div>
            </div>
            <p style="text-align: center; margin-top: 20px;"><em>All deadlines are 11:59 PM Anywhere on Earth (AoE)</em></p>
        </div>
    </section>
    
    <section id="organizers">
        <div class="container">
            <div class="section-heading">
                <h2>Organizers</h2>
            </div>
            <div class="organizers-container">
                <div class="organizer-card">
                    <div class="organizer-image">
                        <img src="nick.jpg" alt="Nick Boffi">
                    </div>
                    <h3><a href="https://nmboffi.github.io" target="_blank">Nick Boffi</a></h3>
                    <p>Carnegie Mellon University</p>
                </div>

                <div class="organizer-card">
                    <div class="organizer-image">
                        <img src="misha.jpg" alt="Misha Khodak">
                    </div>
                    <h3><a href="https://pages.cs.wisc.edu/~khodak/" target="_blank">Misha Khodak</a></h3>
                    <p>Princeton University</p>
                </div>
                
                <div class="organizer-card">
                    <div class="organizer-image">
                        <img src="jianfeng.jpg" alt="Jianfeng Lu">
                    </div>
                    <h3><a href="https://sites.math.duke.edu/~jianfeng/" target="_blank">Jianfeng Lu</a></h3>
                    <p>Duke University</p>
                </div>
                
                <div class="organizer-card">
                    <div class="organizer-image">
                        <img src="tanya.png" alt="Tanya Marwah">
                    </div>
                    <h3><a href="https://tm157.github.io" target="_blank">Tanya Marwah</a></h3>
                    <p>Polymathic AI and the Flatiron Institute</p>
                </div>

                <div class="organizer-card">
                    <div class="organizer-image">
                        <img src="andrej.jpg" alt="Andrej Risteski">
                    </div>
                    <h3><a href="https://www.andrew.cmu.edu/user/aristesk/" target="_blank">Andrej Risteski</a></h3>
                    <p>Carnegie Mellon University</p>
                </div>
            </div>
        </div>
    </section>
    
    <section id="registration">
        <div class="container" style="text-align: center;">
            <div class="section-heading">
                <h2>Registration</h2>
            </div>
            <div class="cfp">
              <p>Registration for the TASC workshop is automatically included in your COLT 2025 conference registration fee; no separate registration is required. To register for COLT 2025, go to the <a href="https://colt2025.univ-lyon1.fr/en/pages/colt-2025-registration-nbsp">COLT 2025 registration website</a> and follow the instructions in the "Registration procedure" section. <b>The early bird registration deadline is May 22.</b></p>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>&copy; 2025 TASC Workshop | Theory of AI for Scientific Computing</p>
        </div>
    </footer>

    <script>
        function toggleDetails(keynoteId) {
            const details = document.getElementById(keynoteId);
            const button = details.previousElementSibling.querySelector('.details-btn');
            const showText = button.getAttribute('data-show-text');
            const hideText = button.getAttribute('data-hide-text');
            
            if (details.classList.contains('show')) {
                details.classList.remove('show');
                button.textContent = showText;
            } else {
                // Hide all other open details first
                document.querySelectorAll('.keynote-details.show').forEach(detail => {
                    detail.classList.remove('show');
                    const otherButton = detail.previousElementSibling.querySelector('.details-btn');
                    otherButton.textContent = otherButton.getAttribute('data-show-text');
                });
                
                // Show the clicked one
                details.classList.add('show');
                button.textContent = hideText;
            }
        }
    </script>
</body>
</html>
